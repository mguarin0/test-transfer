{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import fetch_predictions, calc_basic_performance_metrics\n",
    "\n",
    "test_complex_data = fetch_predictions(persist_dir = \"pl_out/node_average_15_epochs/persist_train_4_layer/\",\n",
    "                                      replica_of_interest = 6,\n",
    "                                      run_type_flag = \"test\")\n",
    "test_complex_data_w_metrics = calc_basic_performance_metrics(test_complex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean auc: +/-0.139713039598 0.83722228028\n",
      " median auc: 0.885546804854\n",
      " (across all complexes)\n",
      "\n",
      " average_precision_score auc: +/-0.0502415056224 0.0569991083649\n",
      " average_precision_score auc: 0.0463167023128\n",
      " (across all complexes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def print_stats(complex_data):\n",
    "    print(\" mean auc: +/-{} {}\\n median auc: {}\\n (across all complexes)\\n\".format(np.std([complex_data[complex_code][\"auc\"] for complex_code in complex_data.keys()]),\n",
    "                                                                                   np.mean([complex_data[complex_code][\"auc\"] for complex_code in complex_data.keys()]),\n",
    "                                                                                   np.median([complex_data[complex_code][\"auc\"] for complex_code in complex_data.keys()])))\n",
    "\n",
    "    print(\" average_precision_score auc: +/-{} {}\\n average_precision_score auc: {}\\n (across all complexes)\\n\".format(np.std([complex_data[complex_code][\"average_precision_score\"] for complex_code in complex_data.keys()]),\n",
    "                                                                                                                       np.mean([complex_data[complex_code][\"average_precision_score\"] for complex_code in complex_data.keys()]),\n",
    "                                                                                                                       np.median([complex_data[complex_code][\"average_precision_score\"] for complex_code in complex_data.keys()])))\n",
    "# end\n",
    "print_stats(test_complex_data_w_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import aggregate_predictions_all_complexes\n",
    "\n",
    "all_y_trues, all_y_preds = aggregate_predictions_all_complexes(test_complex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_y_trues, all_y_preds)\n",
    "roc_auc = auc(fpr, tpr) # compute area under the curve\n",
    "\n",
    "#fpr = sorted(fpr)\n",
    "#tpr = sorted(tpr)\n",
    "#thresholds = sorted(thresholds)\n",
    "\n",
    "default_fontsize = 10\n",
    "x_figure_size = 8\n",
    "y_figure_size = 8\n",
    "\n",
    "plt.figure()\n",
    "lw = 4\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate').set_fontsize(default_fontsize)\n",
    "plt.ylabel('True Positive Rate').set_fontsize(default_fontsize)\n",
    "plt.title('Receiver operating characteristic example').set_fontsize(default_fontsize)\n",
    "plt.legend(loc=\"lower right\", prop={'size': default_fontsize})\n",
    "plt.tick_params(labelsize=default_fontsize)\n",
    "\n",
    "# create the axis of thresholds (scores)\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "ax2.set_ylabel('Threshold', color='red')\n",
    "ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "              ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(default_fontsize)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=x_figure_size, y_figure_size\n",
    "\n",
    "plt.savefig('roc_and_threshold.png')\n",
    "#plt.close()\n",
    "plt.show()\n",
    "\n",
    "# tpr = tp/(tp+fn)\n",
    "# fpr = fp/(fp+tn)\n",
    "# sensitivity = recall = tp / t = tp / (tp + fn)\n",
    "# specificity = tn / n = tn / (tn + fp)\n",
    "# precision = tp / p = tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1103/1105 [20:24<00:02,  1.05s/it]/home/cc/anaconda3/envs/fout_gcn/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "100%|█████████▉| 1104/1105 [20:25<00:01,  1.04s/it]/home/cc/anaconda3/envs/fout_gcn/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "100%|██████████| 1105/1105 [20:26<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx of threshold yielding max precision: 0\n",
      "idx of threshold yielding max recall: 1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import calc_precision_recall\n",
    "from tqdm import tqdm\n",
    "\n",
    "# based on roc curve above choose threshold\n",
    "guess_optimal_threshold = 1.0\n",
    "\n",
    "cutoff_thresholds = [thres for thres in sorted(thresholds) if thres > guess_optimal_threshold]\n",
    "\n",
    "cand_ps = []\n",
    "cand_rs = []\n",
    "\n",
    "def solve_optimal_threshold(cutoff_thresholds):\n",
    "    for pred_threshold in tqdm(cutoff_thresholds):\n",
    "        all_y_preds_pred_threshold = list(map(lambda x: 1 if x > pred_threshold else 0, all_y_preds))\n",
    "        pred_p, pred_r = calc_precision_recall(all_y_preds_pred_threshold, all_y_trues)\n",
    "        cand_ps.append(pred_p)\n",
    "        cand_rs.append(pred_r)\n",
    "    return (cand_ps, cand_rs)\n",
    "# end\n",
    "\n",
    "cand_ps, cand_rs = solve_optimal_threshold(cutoff_thresholds)\n",
    "print(\"idx of threshold yielding max precision: {}\".format(cand_ps.index(max(cand_ps))))\n",
    "print(\"idx of threshold yielding max recall: {}\".format(cand_rs.index(max(cand_rs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222372575553\n",
      "0.0350590243209\n",
      "predicted_dist: Counter({0: 886948, 1: 28124})\n",
      "true_dist: Counter({0: 910638, 1: 4434})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "optimal_\n",
    "optimal_threshold=cutoff_thresholds[]\n",
    "all_y_preds_pred_threshold = list(map(lambda x: 1 if x > optimal_threshold else 0, all_y_preds))\n",
    "print(\"predicted_dist: {}\".format(Counter(all_y_preds_optimal)))\n",
    "print(\"true_dist: {}\".format(Counter(all_y_trues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          default_fontsize,\n",
    "                          x_figure_size,\n",
    "                          y_figure_size, \n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title).set_fontsize(default_fontsize)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tick_params(labelsize=default_fontsize)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 fontsize=default_fontsize,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label').set_fontsize(default_fontsize)\n",
    "    plt.xlabel('Predicted label').set_fontsize(default_fontsize)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"]=x_figure_size, y_figure_size\n",
    "\n",
    "    if normalize:\n",
    "      plt.savefig('normalized_confusion_matrix.png')\n",
    "    else:\n",
    "      plt.savefig('confusion_matrix_without_normalization.png')\n",
    "# end\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(all_y_trues_recast, all_y_preds_optimal)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "default_fontsize = 20\n",
    "x_figure_size = 12\n",
    "y_figure_size = 12\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      default_fontsize,\n",
    "                      x_figure_size,\n",
    "                      y_figure_size,\n",
    "                      classes=[\"No Interaction\", \"Interaction\"],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\"\"\"\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      default_fontsize,\n",
    "                      x_figure_size,\n",
    "                      y_figure_size,\n",
    "                      classes=[\"No Interaction\", \"Interaction\"], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\"\"\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers of interest\n",
    "# https://arxiv.org/pdf/1801.07829.pdf "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
